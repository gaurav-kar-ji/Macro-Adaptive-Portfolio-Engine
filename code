{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gaurav11062002/macro-adaptive-portfolio-engine?scriptVersionId=286197779\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Macro-Adaptive Core–Satellite Portfolio Engine\n\nThis project builds a **regime-aware, institutionally realistic portfolio system**.\n\nDesign philosophy:\n- Do NOT chase headline Sharpe\n- Control risk explicitly\n- Separate **alpha quality** from **portfolio engineering**\n- Benchmark against what institutions actually use\n\nThis is an **allocator / quant-engineering project**, not a pure alpha paper.\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELL 1: ENVIRONMENT SETUP & DETERMINISM\n# Purpose:\n# - Reproducibility\n# - Research-grade imports only\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.covariance import LedoitWolf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(42)\npd.set_option(\"display.float_format\", \"{:.4f}\".format)\n\nprint(\"Environment ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:18:18.411888Z","iopub.execute_input":"2025-12-14T19:18:18.41214Z","iopub.status.idle":"2025-12-14T19:18:19.449928Z","shell.execute_reply.started":"2025-12-14T19:18:18.41212Z","shell.execute_reply":"2025-12-14T19:18:19.449146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 2: EXPANDED ASSET UNIVERSE\n# Purpose:\n# - Increase cross-sectional breadth\n# - Improve residual signal quality\n# ============================================================\n\n# Define the missing function\ndef load_prices(tickers, start_date='2000-01-01', end_date='2024-06-01'):\n    print(f\"Downloading data for {len(tickers)} assets...\")\n    data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=True)['Close']\n    \n    # Handle MultiIndex if present\n    if isinstance(data.columns, pd.MultiIndex):\n        data.columns = data.columns.get_level_values(0)\n    \n    # CRITICAL: Remove Timezones to prevent \"Timestamp vs Float\" errors\n    data.index = pd.to_datetime(data.index).tz_localize(None)\n    \n    return data.ffill().dropna()\n\nASSETS = [\n    # Equity Regions\n    \"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"EEM\",\n    # Equity Sectors\n    \"XLK\", \"XLF\", \"XLE\", \"XLV\", \"XLI\",\n    # Rates\n    \"TLT\", \"IEF\", \"SHY\",\n    # Commodities\n    \"GLD\", \"DBC\", \"USO\",\n    # Real Assets\n    \"VNQ\"\n]\n\n# Now the function exists and can be called\nprices = load_prices(ASSETS)\nreturns = prices.pct_change().dropna()\n\nprint(f\"Expanded universe loaded: {len(ASSETS)} assets.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:18:19.45132Z","iopub.execute_input":"2025-12-14T19:18:19.451758Z","iopub.status.idle":"2025-12-14T19:18:21.195623Z","shell.execute_reply.started":"2025-12-14T19:18:19.451737Z","shell.execute_reply":"2025-12-14T19:18:21.195046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 3: REGIME FEATURES\n# Purpose:\n# - Observable regime signals\n# - No hidden-state leakage\n# ============================================================\n\ndef realized_vol(series, window=21):\n    return series.rolling(window).std() * np.sqrt(252)\n\ndef avg_correlation(returns, window=63):\n    corr = returns.rolling(window).corr()\n    return corr.groupby(level=0).mean().mean(axis=1)\n\ndef hurst_exponent(series):\n    lags = range(2, 20)\n    tau = [np.std(series.diff(l).dropna()) for l in lags]\n    return np.polyfit(np.log(lags), np.log(tau), 1)[0]\n\ndef rolling_hurst(series, window=252):\n    return series.rolling(window).apply(lambda x: hurst_exponent(pd.Series(x)), raw=False)\n\nregime_df = pd.DataFrame(index=returns.index)\nregime_df[\"vol\"] = realized_vol(returns.mean(axis=1))\nregime_df[\"corr\"] = avg_correlation(returns)\nregime_df[\"trend\"] = rolling_hurst(returns.mean(axis=1))\nregime_df = regime_df.dropna()\n\nprint(\"Regime features constructed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:18:21.196443Z","iopub.execute_input":"2025-12-14T19:18:21.196745Z","iopub.status.idle":"2025-12-14T19:18:35.039926Z","shell.execute_reply.started":"2025-12-14T19:18:21.196702Z","shell.execute_reply":"2025-12-14T19:18:35.039163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 4: REGIME CLUSTERING (NO REFITTING)\n# Purpose:\n# - Train on pre-2020\n# - Freeze model\n# ============================================================\n\nTRAIN_END = \"2019-12-31\"\n\nregime_train = regime_df.loc[:TRAIN_END]\nregime_full  = regime_df.copy()\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(regime_train)\n\nkmeans = KMeans(n_clusters=3, random_state=42, n_init=20)\nkmeans.fit(X_train)\n\nregime_full[\"regime\"] = kmeans.predict(scaler.transform(regime_full))\nregime_df = regime_full\n\nprint(\"Regimes trained and frozen.\")\nprint(regime_df[\"regime\"].value_counts(normalize=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:18:35.040775Z","iopub.execute_input":"2025-12-14T19:18:35.041051Z","iopub.status.idle":"2025-12-14T19:18:35.142113Z","shell.execute_reply.started":"2025-12-14T19:18:35.041031Z","shell.execute_reply":"2025-12-14T19:18:35.141452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 5: RESIDUAL MOMENTUM (LAGGED MARKET)\n# Purpose:\n# - Remove market beta safely\n# ============================================================\n\ndef compute_residual_momentum(returns, lookback=126):\n    residuals = pd.DataFrame(index=returns.index, columns=returns.columns)\n    mkt = returns[\"SPY\"]\n\n    for asset in returns.columns:\n        if asset == \"SPY\":\n            continue\n\n        model = LinearRegression()\n\n        for t in range(lookback + 1, len(returns)):\n            y = returns[asset].iloc[t-lookback:t]\n            X = mkt.iloc[t-lookback:t].values.reshape(-1, 1)\n            model.fit(X, y)\n\n            pred = model.predict([[mkt.iloc[t-1]]])[0]  # LAGGED\n            residuals.iloc[t][asset] = returns.iloc[t][asset] - pred\n\n    return residuals.astype(float)\n\nresidual_returns = compute_residual_momentum(returns)\nresidual_mom = residual_returns.rolling(126).sum()\n\nprint(\"Residual momentum computed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:18:35.143945Z","iopub.execute_input":"2025-12-14T19:18:35.144154Z","iopub.status.idle":"2025-12-14T19:19:37.390171Z","shell.execute_reply.started":"2025-12-14T19:18:35.144138Z","shell.execute_reply":"2025-12-14T19:19:37.389492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 6: GLOBAL RISK CONSTRAINTS\n# ============================================================\n\nTARGET_VOL = 0.10\nVOL_FLOOR  = 0.05\nMAX_GROSS  = 1.2\nMAX_ASSET  = 0.30\nDD_STOP_1  = -0.20\nDD_STOP_2  = -0.30\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:37.390927Z","iopub.execute_input":"2025-12-14T19:19:37.391215Z","iopub.status.idle":"2025-12-14T19:19:37.395199Z","shell.execute_reply.started":"2025-12-14T19:19:37.391195Z","shell.execute_reply":"2025-12-14T19:19:37.394524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 7: PORTFOLIO CONSTRUCTION\n# ============================================================\n\ndef build_portfolio(date, equity_curve):\n\n    mom = residual_mom.loc[:date].iloc[-1].dropna()\n    if mom.empty:\n        return pd.Series(0.0, index=returns.columns)\n\n    top_assets = mom.sort_values(ascending=False).head(3).index\n    ret_window = returns.loc[:date, top_assets].iloc[-252:]\n\n    cov = LedoitWolf().fit(ret_window).covariance_\n    vols = np.sqrt(np.diag(cov))\n\n    weights = (1 / vols)\n    weights = weights / weights.sum()\n    weights = pd.Series(weights, index=top_assets)\n\n    port_vol = np.sqrt(weights.T @ cov @ weights)\n    port_vol = max(port_vol, VOL_FLOOR)\n    weights *= TARGET_VOL / port_vol\n\n    # --- Regime-based scaling ---\n    high_vol_regime = regime_df.groupby(\"regime\")[\"vol\"].mean().idxmax()\n    current_regime = regime_df.loc[:date].iloc[-1][\"regime\"]\n    if current_regime == high_vol_regime:\n        weights *= 0.6\n\n    # --- Caps ---\n    weights = weights.clip(-MAX_ASSET, MAX_ASSET)\n    gross = weights.abs().sum()\n    if gross > MAX_GROSS:\n        weights *= MAX_GROSS / gross\n\n    # --- Drawdown kill-switch ---\n    if len(equity_curve) > 252:\n        peak = equity_curve.cummax().iloc[-1]\n        dd = equity_curve.iloc[-1] / peak - 1\n        if dd < DD_STOP_2:\n            return pd.Series(0.0, index=returns.columns)\n        if dd < DD_STOP_1:\n            weights *= 0.5\n\n    final = pd.Series(0.0, index=returns.columns)\n    final.update(weights)\n    return final\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:37.395918Z","iopub.execute_input":"2025-12-14T19:19:37.396162Z","iopub.status.idle":"2025-12-14T19:19:37.410261Z","shell.execute_reply.started":"2025-12-14T19:19:37.396138Z","shell.execute_reply":"2025-12-14T19:19:37.409699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 8: ALPHA ENGINE (Fixed - No External Dependencies)\n# Purpose: Generate 'net_returns' for Cell 8A\n# ============================================================\n\nimport pandas as pd\nimport numpy as np\n\n# 1. Prepare Returns (Required for Cell 8A)\n# We calculate daily percentage changes from the prices loaded in Cell 2B\nreturns = prices.pct_change().dropna()\n\n# 2. Define the Alpha Strategy (Concentrated Momentum)\n# This engine picks the Top 3 performing assets every month\ndef get_alpha_weights(prices_window):\n    # Momentum Lookback: 126 days (6 months)\n    # Check if we have enough data\n    if len(prices_window) < 126:\n        return pd.Series(0.0, index=prices_window.columns)\n\n    momentum = prices_window.pct_change(126).iloc[-1]\n    \n    # Trend Filter: Price > 200-day Moving Average\n    ma200 = prices_window.rolling(200).mean().iloc[-1]\n    ma200 = ma200.fillna(0)\n    \n    current_prices = prices_window.iloc[-1]\n    uptrend = current_prices > ma200\n    \n    # Select Assets: Positive Momentum + In Uptrend\n    # Ensure we align indices correctly\n    valid_assets = momentum.index.intersection(uptrend.index)\n    \n    # Filter for assets that are UP (Positive Mom) and HEALTHY (Above MA)\n    eligible = momentum[valid_assets][(momentum[valid_assets] > 0) & (uptrend[valid_assets])].index\n    \n    # Weighting: Equal Weight Top 3\n    weights = pd.Series(0.0, index=prices_window.columns)\n    \n    if len(eligible) > 0:\n        # Pick top 3 highest momentum assets\n        top_picks = momentum[eligible].sort_values(ascending=False).head(3).index\n        weights[top_picks] = 1.0 / len(top_picks)\n    else:\n        # Fallback: Defensive Posture\n        # If 'SHY' (Cash) is available, go 100% Cash. Otherwise 'TLT' (Bonds).\n        defensive = 'SHY' if 'SHY' in prices_window.columns else 'TLT'\n        if defensive in prices_window.columns:\n            weights[defensive] = 1.0\n            \n    return weights\n\n# 3. Run the Walk-Forward Backtest\nprint(\"Generating Alpha Strategy Returns...\")\nhistory = []\n\n# Generate rebalance dates (Month-End)\n# We handle potential index issues by resampling explicitly\ntry:\n    # Use the available price index to generate monthly dates\n    start_date = prices.index[252] # Skip first year for warmup\n    rebalance_dates = prices.resample('ME').last().index\n    rebalance_dates = rebalance_dates[rebalance_dates > start_date]\nexcept Exception as e:\n    # Fallback for different pandas versions\n    rebalance_dates = prices.resample('M').last().index\n    rebalance_dates = rebalance_dates[rebalance_dates > prices.index[252]]\n\nfor date in rebalance_dates:\n    # No look-ahead bias: Use data only up to this specific date\n    window = prices.loc[:date]\n    \n    w = get_alpha_weights(window)\n    w.name = date\n    history.append(w)\n\n# 4. Calculate Net Returns (The variable Cell 8A needs)\nalpha_weights_df = pd.DataFrame(history)\n# Ensure index is Datetime\nalpha_weights_df.index = pd.to_datetime(alpha_weights_df.index)\n\n# Reindex to daily data and shift by 1 day (Trade at Open/Close of next day)\naligned_weights = alpha_weights_df.reindex(returns.index).ffill().shift(1).fillna(0)\n\n# Calculate portfolio returns\ngross_returns = (aligned_weights * returns).sum(axis=1)\n\n# Subtract Transaction Costs (10bps)\nturnover = aligned_weights.diff().abs().sum(axis=1)\nnet_returns = gross_returns - (turnover * 0.0010)\n\nprint(f\"Alpha Strategy Generated. CAGR: {((1+net_returns).prod()**(252/len(net_returns))-1):.1%}\")\nprint(\"Variable 'net_returns' is now defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:37.410945Z","iopub.execute_input":"2025-12-14T19:19:37.411578Z","iopub.status.idle":"2025-12-14T19:19:38.878828Z","shell.execute_reply.started":"2025-12-14T19:19:37.411559Z","shell.execute_reply":"2025-12-14T19:19:38.878215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 9: CORE–SATELLITE BACKTEST\n# Core   = Trend Following\n# Satellite = Residual Momentum Alpha\n# ============================================================\n\n# ---------- CORE: TREND PORTFOLIO ----------\ntrend_signal = (prices > prices.rolling(200).mean()).astype(int)\ntrend_weights = trend_signal.div(trend_signal.sum(axis=1), axis=0).fillna(0)\ntrend_returns = (trend_weights * returns).sum(axis=1)\n\n# ---------- SATELLITE: YOUR ALPHA ----------\nalpha_returns = net_returns.copy()\n\n# ---------- CORE–SATELLITE MIX ----------\nCORE_WEIGHT = 0.70\nALPHA_WEIGHT = 0.30\n\ncs_returns = (\n    CORE_WEIGHT * trend_returns +\n    ALPHA_WEIGHT * alpha_returns\n)\n\ncs_equity = (1 + cs_returns).cumprod()\n\nprint(\"Core–Satellite portfolio constructed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:38.879488Z","iopub.execute_input":"2025-12-14T19:19:38.87981Z","iopub.status.idle":"2025-12-14T19:19:38.897265Z","shell.execute_reply.started":"2025-12-14T19:19:38.879792Z","shell.execute_reply":"2025-12-14T19:19:38.896585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 10: REGIME-CONDITIONAL CORE–SATELLITE\n# Purpose:\n# - Activate alpha ONLY when trend weak\n# ============================================================\n\n# --- Trend strength (breadth) ---\ntrend_strength = trend_signal.mean(axis=1)\n\n# --- Alpha active only when trend < threshold ---\nALPHA_ACTIVE_THRESHOLD = 0.60\n\nalpha_gate = (trend_strength < ALPHA_ACTIVE_THRESHOLD).astype(int)\n\ncs_returns = (\n    CORE_WEIGHT * trend_returns +\n    ALPHA_WEIGHT * alpha_returns * alpha_gate\n)\n\ncs_equity = (1 + cs_returns).cumprod()\n\nprint(\"Regime-conditional core–satellite portfolio constructed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:38.897983Z","iopub.execute_input":"2025-12-14T19:19:38.89885Z","iopub.status.idle":"2025-12-14T19:19:38.906958Z","shell.execute_reply.started":"2025-12-14T19:19:38.898826Z","shell.execute_reply":"2025-12-14T19:19:38.906185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 11: METRICS FUNCTION DEFINITION\n# Purpose: Define the 'metrics' function required by Cell 9A\n# ============================================================\nimport numpy as np\nimport pandas as pd\n\ndef metrics(returns_series):\n    \"\"\"\n    Calculates performance metrics: CAGR, Volatility, Sharpe, Max Drawdown\n    \"\"\"\n    # 1. Cumulative Wealth Curve\n    cumulative = (1 + returns_series).cumprod()\n    \n    # 2. CAGR (Compound Annual Growth Rate)\n    # Number of years = total trading days / 252\n    n_years = len(returns_series) / 252\n    total_return = cumulative.iloc[-1]\n    cagr = total_return ** (1 / n_years) - 1\n    \n    # 3. Annualized Volatility\n    vol = returns_series.std() * np.sqrt(252)\n    \n    # 4. Sharpe Ratio (assuming 0% risk-free rate)\n    if vol == 0:\n        sharpe = 0\n    else:\n        sharpe = (cagr) / vol\n        \n    # 5. Max Drawdown\n    peak = cumulative.cummax()\n    drawdown = (cumulative - peak) / peak\n    max_drawdown = drawdown.min()\n    \n    return cagr, vol, sharpe, max_drawdown\n\nprint(\"Function 'metrics' is now defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:38.907697Z","iopub.execute_input":"2025-12-14T19:19:38.907918Z","iopub.status.idle":"2025-12-14T19:19:38.917263Z","shell.execute_reply.started":"2025-12-14T19:19:38.907894Z","shell.execute_reply":"2025-12-14T19:19:38.916686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 12: CORE–SATELLITE PERFORMANCE\n# ============================================================\n\ncagr, vol, sharpe, mdd = metrics(cs_returns)\n\nprint(\"=== CORE–SATELLITE PERFORMANCE ===\")\nprint(f\"CAGR: {cagr:.2%}\")\nprint(f\"Volatility: {vol:.2%}\")\nprint(f\"Sharpe: {sharpe:.2f}\")\nprint(f\"Max Drawdown: {mdd:.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:38.917913Z","iopub.execute_input":"2025-12-14T19:19:38.918137Z","iopub.status.idle":"2025-12-14T19:19:38.93143Z","shell.execute_reply.started":"2025-12-14T19:19:38.918116Z","shell.execute_reply":"2025-12-14T19:19:38.930854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 13: EQUITY CURVE (Fixed)\n# ============================================================\n\nplt.figure(figsize=(14,6))\n\n# Change 'equity_curve' to 'cs_equity' (the variable calculated in Cell 8)\nplt.plot(cs_equity, label=\"Residual Momentum Strategy\", lw=2)\n\nplt.title(\"Regime-Conditional Residual Momentum Strategy\")\nplt.ylabel(\"Growth of $1\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:38.932033Z","iopub.execute_input":"2025-12-14T19:19:38.932243Z","iopub.status.idle":"2025-12-14T19:19:39.181874Z","shell.execute_reply.started":"2025-12-14T19:19:38.93222Z","shell.execute_reply":"2025-12-14T19:19:39.181116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 14: INSTITUTIONAL BENCHMARK COMPARISON\n# Purpose:\n# - Compare strategy vs real institutional benchmarks\n# - Output BOTH table and equity curve plot\n# ============================================================\n\n# ---------- ALIGN DATA ----------\ncommon_idx = net_returns.index.intersection(returns.index)\nstrat = net_returns.loc[common_idx]\n\nbench = pd.DataFrame(index=common_idx)\n\n# ---------- 60/40 POLICY PORTFOLIO ----------\nbench[\"60_40\"] = (\n    0.6 * returns.loc[common_idx, \"SPY\"] +\n    0.4 * returns.loc[common_idx, \"TLT\"]\n)\n\n# ---------- RISK PARITY (INVERSE VOL, 1Y LOOKBACK) ----------\nvol = returns.loc[common_idx].rolling(252).std()\ninv_vol = 1 / vol\nrp_weights = inv_vol.div(inv_vol.sum(axis=1), axis=0)\nbench[\"Risk_Parity\"] = (rp_weights * returns.loc[common_idx]).sum(axis=1)\n\n# ---------- TIME-SERIES MOMENTUM (TREND) ----------\ntrend_signal = (prices.loc[common_idx] > prices.loc[common_idx].rolling(200).mean()).astype(int)\ntrend_weights = trend_signal.div(trend_signal.sum(axis=1), axis=0).fillna(0)\nbench[\"Trend\"] = (trend_weights * returns.loc[common_idx]).sum(axis=1)\n\nbench = bench.dropna()\nstrat = strat.loc[bench.index]\n\n# ---------- PERFORMANCE METRICS ----------\ndef perf_stats(r):\n    cum = (1 + r).cumprod()\n    return pd.Series({\n        \"CAGR\": cum.iloc[-1] ** (252 / len(cum)) - 1,\n        \"Volatility\": r.std() * np.sqrt(252),\n        \"Sharpe\": (cum.iloc[-1] ** (252 / len(cum)) - 1) / (r.std() * np.sqrt(252)),\n        \"Max Drawdown\": (cum / cum.cummax() - 1).min()\n    })\n\nsummary = pd.concat(\n    [perf_stats(strat), bench.apply(perf_stats)],\n    axis=1\n).T\n\nsummary.index = [\n    \"Residual_Momentum_Strategy\",\n    \"60_40_Policy\",\n    \"Risk_Parity\",\n    \"Trend_Following\"\n]\n\nprint(\"=== Institutional Performance Comparison ===\")\nsummary\n\n# ---------- EQUITY CURVE PLOT ----------\nplt.figure(figsize=(14,6))\n\nplt.plot((1 + strat).cumprod(), lw=2.5, label=\"Residual Momentum Strategy\")\n\nfor col in bench.columns:\n    plt.plot((1 + bench[col]).cumprod(), lw=1.5, linestyle=\"--\", label=col)\n\nplt.title(\"Strategy vs Institutional Benchmarks\")\nplt.ylabel(\"Growth of $1\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:39.184305Z","iopub.execute_input":"2025-12-14T19:19:39.184551Z","iopub.status.idle":"2025-12-14T19:19:39.500477Z","shell.execute_reply.started":"2025-12-14T19:19:39.184534Z","shell.execute_reply":"2025-12-14T19:19:39.499905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 15: DEFLATED SHARPE (BAILEY et al.)\n# Purpose:\n# - Penalize multiple testing\n# - Kill backtest overconfidence\n# ============================================================\n\ndef deflated_sharpe(sr, T, trials=50):\n    gamma = 0.5772156649\n    sr_adj = sr - (gamma * np.sqrt((1 - sr**2) / (T - 1)))\n    return sr_adj\n\nT = len(net_returns)\nraw_sharpe = sharpe\ndsr = deflated_sharpe(raw_sharpe, T)\n\nprint(f\"Raw Sharpe: {raw_sharpe:.2f}\")\nprint(f\"Deflated Sharpe: {dsr:.2f}\")\n\n# --- Simple overfitting diagnostic ---\nprint(\"Sharpe > 0.5 (raw):\", raw_sharpe > 0.5)\nprint(\"Sharpe > 0.5 (deflated):\", dsr > 0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:39.501076Z","iopub.execute_input":"2025-12-14T19:19:39.501268Z","iopub.status.idle":"2025-12-14T19:19:39.506587Z","shell.execute_reply.started":"2025-12-14T19:19:39.501252Z","shell.execute_reply":"2025-12-14T19:19:39.506023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CELL 16: ALPHA ATTRIBUTION (Fixed)\n# Purpose:\n# - Decompose returns\n# ============================================================\nimport matplotlib.pyplot as plt\n\nattr = pd.DataFrame(index=net_returns.index)\n\n# --- Signal-only (no vol targeting) ---\n# FIX: Use 'aligned_weights' instead of 'weights'\nsignal_only = aligned_weights.copy()\n\n# Normalize weights to sum to 1 (isolates the signal quality from leverage)\nrow_sums = signal_only.abs().sum(axis=1)\n# Avoid division by zero\nsignal_only = signal_only.div(row_sums.replace(0, 1), axis=0)\n\nattr[\"Signal\"] = (signal_only * returns).sum(axis=1)\n\n# --- Leverage effect ---\n# The difference between your actual strategy return and the un-levered signal\nattr[\"Leverage\"] = net_returns - attr[\"Signal\"]\n\n# --- Market exposure ---\nattr[\"Market\"] = returns[\"SPY\"]\n\n# --- Cumulative attribution ---\n(attr + 1).cumprod().plot(\n    figsize=(14,6),\n    title=\"Alpha Attribution: Signal vs Leverage vs Market\"\n)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:19:39.507239Z","iopub.execute_input":"2025-12-14T19:19:39.507463Z","iopub.status.idle":"2025-12-14T19:19:39.802696Z","shell.execute_reply.started":"2025-12-14T19:19:39.507433Z","shell.execute_reply":"2025-12-14T19:19:39.801848Z"}},"outputs":[],"execution_count":null}]}